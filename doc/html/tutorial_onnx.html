<!--%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  Copyright (c) 2016-2018 Qualcomm Technologies, Inc.
  All Rights Reserved.
  Confidential and Proprietary - Qualcomm Technologies, Inc.
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
-->
<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"></meta>
<meta http-equiv="X-UA-Compatible" content="IE=9"></meta>
<title>Snapdragon Neural Processing Engine SDK: Running a ONNX Model with SNPE SDK</title>
<link href="tabs.css" rel="stylesheet" type="text/css"></link>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="autoEnterCurrentDate.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="is.css" rel="stylesheet" type="text/css" ></link>
<link href="custom.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">Snapdragon Neural Processing Engine SDK
   <span id="projectnumber"></span></div>
   <div id="projectbrief">Reference Guide</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('tutorial_onnx.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Running a ONNX Model with SNPE SDK </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="tutorial_onnx_Table_Of_Contents"></a>
Table Of Contents</h1>
<ul>
<li>
<a class="el" href="tutorial_onnx.html#tutorial_onnx_Objective">Objective</a> <br />
 </li>
<li>
<a class="el" href="tutorial_onnx.html#tutorial_onnx_Description">Description</a> <br />
 </li>
<li>
<a class="el" href="tutorial_onnx.html#tutorial_onnx_RunningTheExample">Running The Example</a> <br />
 </li>
</ul>
<h1><a class="anchor" id="tutorial_onnx_Objective"></a>
Objective</h1>
<p>This example imports a pretrained VGG model from the ONNX framework, and demonstrates inference.</p>
<h1><a class="anchor" id="tutorial_onnx_Description"></a>
Description</h1>
<p>This example shows how to run an ONNX model using the SNPE SDK. We will perform the following steps:</p>
<ul>
<li>
Set up the ONNX environment for converting the VGG-16 model into a DLC, using <em>snpe-onnx-to-dlc</em>. </li>
<li>
Download the ONNX pre-trained VGG model and preprocess input image. </li>
<li>
Convert the VGG model to DLC format, using <em>snpe-onnx-to-dlc</em>. Use <em>snpe-dlc-info</em> to visualize the converted network structure. </li>
<li>
Execute on your SNPE compatible device, using <em>snpe-net-run</em>, and postprocess the result for prediction. </li>
</ul>
<h1><a class="anchor" id="tutorial_onnx_RunningTheExample"></a>
Running The Example</h1>
<ol>
<li>
<p class="startli">First set up ONNX environment </p><pre class="fragment">cd $SNPE_ROOT
source bin/envsetup.sh -o $ONNX_DIR
  where $ONNX_DIR is the path to the ONNX installation.</pre><p> The script sets up the following environment variables. </p><pre class="fragment">SNPE_ROOT: root directory of the SNPE SDK installation
ONNX_HOME: root directory of the ONNX installation provided</pre><p>The script also updates PATH, LD_LIBRARY_PATH, and PYTHONPATH.</p>
<p>You should be able to run <em>snpe-onnx-to-dlc</em> <em>-h</em> without error if the environment is set correctly.</p>
<p class="endli"></p>
</li>
<li>
<p class="startli">Download the VGG pretrained model <br />
 Download the ONNX pretrained VGG model from <a href="https://s3.amazonaws.com/onnx-model-zoo/vgg/vgg16/vgg16.onnx" target="_blank">here</a>. </p><pre class="fragment">cd $SNPE_ROOT/models/VGG
wget https://s3.amazonaws.com/onnx-model-zoo/vgg/vgg16/vgg16.onnx</pre><p>You can find more information about the ONNX VGG model <a href="https://github.com/onnx/models/tree/master/vision/classification/vgg#vgg" target="_blank">here</a></p>
<p class="endli"></p>
</li>
<li>
<p class="startli">Download a sample image, and the label file for the model. </p><pre class="fragment">cd $SNPE_ROOT/models/VGG/data
wget https://s3.amazonaws.com/model-server/inputs/kitten.jpg
wget https://s3.amazonaws.com/onnx-model-zoo/synset.txt</pre><p class="endli">The size of the input image is not limited. </p><dl class="section note"><dt>Note</dt><dd>You can use your own image.</dd></dl>
</li>
<li>
<p class="startli">Preprocess the image and convert it into a raw file. </p><ol>
<li>
Resize to 256x256 </li>
<li>
Take center crop of 224x224 </li>
<li>
Normalize </li>
<li>
Save as a raw file </li>
</ol>
<pre class="fragment">cd $SNPE_ROOT/models/VGG/
python scripts/create_VGG_raws.py -i data/ -d data/cropped/</pre><p>If you see this message, it means the image is preprocessed successfully. </p><pre class="fragment">Preprocessed successfully!</pre><p class="endli"></p>
</li>
<li>
<p class="startli">Convert the ONNX model into SNPE DLC format. </p><pre class="fragment">cd $SNPE_ROOT/models/VGG
snpe-onnx-to-dlc -i onnx/vgg16.onnx -o dlc/vgg16.dlc</pre><p>You should see the following messages: </p><pre class="fragment">INFO - INFO_DLC_SAVE_LOCATION: Saving model at dlc/vgg16.dlc
INFO - INFO_CONVERSION_SUCCESS: Conversion completed successfully</pre><dl class="section note"><dt>Note</dt><dd>From step 2 to step 5, it is equivalent to running "python3 $SNPE_ROOT/models/VGG/scripts/setup_VGG.py" <pre class="fragment">usage: $SNPE_ROOT/models/VGG/scripts/setup_VGG.py [-h] -a ASSETS_DIR [-d]

Prepares the VGG assets for tutorial examples.

required arguments:
  -a ASSETS_DIR, --assets_dir ASSETS_DIR
                        directory containing the VGG assets

optional arguments:
  -d, --download        Download VGG assets to VGG example directory
</pre></dd></dl>
</li>
<li>
<p class="startli">View your DLC model using <em>snpe-dlc-info</em> Execute <code>snpe-dlc-info -i dlc/vgg16.dlc</code> and you will see each layer information in detailed.</p>
<p>Here is a quick snapshot: </p><pre class="fragment">   DLC info for: $SNPE_ROOT/models/VGG/dlc/vgg16.dlc
   Model Version: N/A
   Model Copyright:N/A
   -----------------------------------------------------------------------------------------------------------------------------------------------------------
   | Id | Name                 | Type            | Inputs             | Outputs            | Out Dims      | Runtimes | Parameters                           |
   -----------------------------------------------------------------------------------------------------------------------------------------------------------
   | 0  | data                 | data            | data               | data               | 1x224x224x3   | A D G C  | input_preprocessing: passthrough     |
   |    |                      |                 |                    |                    |               |          | input_type: default                  |
   | 1  | vgg0_conv0_fwd       | convolutional   | data               | vgg0_conv0_fwd     | 1x224x224x64  | A D G C  | padding x: 1                         |
   |    |                      |                 |                    |                    |               |          | padding y: 1                         |
   |    |                      |                 |                    |                    |               |          | padding mode: zero                   |
   |    |                      |                 |                    |                    |               |          | stride x: 1                          |
   |    |                      |                 |                    |                    |               |          | stride y: 1                          |
   |    |                      |                 |                    |                    |               |          | num filters: 64                      |
   |    |                      |                 |                    |                    |               |          | kernel: 3x3                          |
   |    |                      |                 |                    |                    |               |          | param count: 1k (0.0013%)            |
   |    |                      |                 |                    |                    |               |          | MACs per inference: 86M (0.56%)      |
   | 2  | vgg0_relu0_fwd       | neuron          | vgg0_conv0_fwd     | vgg0_relu0_fwd     | 1x224x224x64  | A D G C  | a: 0                                 |
   |    |                      |                 |                    |                    |               |          | b: 0                                 |
   |    |                      |                 |                    |                    |               |          | min_clamp: 0                         |
   |    |                      |                 |                    |                    |               |          | max_clamp: 0                         |
   |    |                      |                 |                    |                    |               |          | func: relu                           |
   .
   .
   .
   | 39 | flatten_70           | reshape         | vgg0_dropout1_fwd  | flatten_70         | 1x4096        | A D G C  |                                      |
   | 40 | vgg0_dense2_fwd      | fully_connected | flatten_70         | vgg0_dense2_fwd    | 1x1000        | A D G C  | param count: 4M (2.96%)              |
   |    |                      |                 |                    |                    |               |          | MACs per inference: 4M (0.0265%)     |
   -----------------------------------------------------------------------------------------------------------------------------------------------------------
   Note: The supported runtimes column assumes a processor target of Snapdragon 835 (8998)
   Key : A:AIP
         D:DSP
         G:GPU
         C:CPU

   Total parameters: 138348355 (527 MB assuming single precision float)
   Total MACs per inference: 15471M (100%)
   Converter command: snpe-onnx-to-dlc input_encoding=[] copyright_file=None disable_batchnorm_folding=False dry_run=None model_version=None input_type=[] validation_target=[] debug=-1 enable_strict_
   validation=False
   DLC created with converter version: X.Y.Z
   Layers used by DLC: CONVOLUTIONAL, DATA, FULLY_CONNECTED, NEURON, PERMUTE, POOLING, RESHAPE
   Est. Steady-State Memory Needed to Run: 965.9 MiB</pre><p>This tool shows the name, dimensions and important parameters of each layer. Additionally, it shows enabled runtimes.</p>
<p class="endli"></p>
</li>
<li>
<p class="startli"><a class="el" href="tools.html#tools_snpe-net-run">Run inference</a>: <em>snpe-net-run</em> loads a DLC file, loads the data for the input tensor(s), and executes the network on the specified runtime. </p><pre class="fragment">cd $SNPE_ROOT/models/VGG/data
snpe-net-run --input_list raw_list.txt --container ../dlc/vgg16.dlc --output_dir ../output</pre><p>You will see the following: </p><pre class="fragment">-------------------------------------------------------------------------------
Model String: N/A
SNPE vX.Y.Z
-------------------------------------------------------------------------------
Processing DNN input(s):
kitten.raw</pre><p class="endli"></p>
</li>
<li>
<p class="startli">Postprocess the result for prediction </p><pre class="fragment">cd $SNPE_ROOT/models/VGG/
python scripts/show_vgg_classifications.py -i data/raw_list.txt -o output/ -l data/synset.txt</pre><p class="endli"></p>
</li>
<li>
<p class="startli">You will see the following, and it means the example ran successfully!</p>
<pre class="fragment">Classification results
probability=0.351833 ; class=n02123045 tabby, tabby cat
probability=0.315166 ; class=n02123159 tiger cat
probability=0.313086 ; class=n02124075 Egyptian cat
probability=0.012995 ; class=n02127052 lynx, catamount
probability=0.003528 ; class=n02129604 tiger, Panthera tigris</pre><p class="endli"></p>
</li>
</ol>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!--%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  Copyright (c) 2016-2018 Qualcomm Technologies, Inc.
  All Rights Reserved.
  Confidential and Proprietary - Qualcomm Technologies, Inc.
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 -->
<!-- start footer part -->
<div id="nav-path" class="navpath" font-size:small;><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">
      <p align="right">
        80-NL315-14 A <br>
        MAY CONTAIN U.S. AND INTERNATIONAL EXPORT CONTROLLED INFORMATION
        <!--If the Controlled Distribution statement is to be included, uncomment below:-->
        <!--<b>Controlled Distribution - DO NOT COPY</b>-->
        <img class="footer" width:5%; alt="QTI Logo" src="images/QTI_Logo.png" />
      </p>
    </li>
  </ul>
</div>
</body>
</html>
